# 📚 英语词汇量统计工具

专业的英语词汇量统计工具，支持三种文件类型的批量处理，基于三遍验证技术确保统计准确性。

## ✨ 功能特点

- ✅ **三种文件类型支持**：1双语、2原文、3外教
- ✅ **智能中文过滤**：自动识别并过滤中文字符
- ✅ **三遍验证机制**：使用三种方法交叉验证，确保准确性
- ✅ **Markdown处理**：智能处理外教对话中的Markdown标记
- ✅ **详细报告**：生成包含汇总、唯一词列表、验证详情的TXT报告
- ✅ **Web界面**：简洁易用的Streamlit界面

## 🚀 快速开始

### 本地运行

1. **安装依赖**

```bash
pip install -r requirements.txt
```

2. **启动应用**

```bash
streamlit run app.py
```

3. **打开浏览器**

访问 http://localhost:8501

### 使用步骤

1. **上传文件**：上传一本书的3个文件
   - `1双语-xxx.txt` - 中英文混合内容
   - `2原文-xxx.txt` - 纯英文原文
   - `3外教-xxx.md` - 双语对话

2. **开始统计**：点击"开始统计"按钮

3. **查看结果**：查看每种类型的详细统计

4. **下载报告**：下载TXT格式的完整报告

## 📊 统计指标

- **总词数**：文本中所有英文单词的数量（含重复）
- **唯一词数**：去重后的不同单词数量
- **验证状态**：三遍验证的结果（通过/差异）
- **高频词**：出现频率最高的单词列表

## 🔍 三遍验证机制

使用三种方法交叉验证统计准确性：

1. **方法1**：正则表达式 `\b[a-zA-Z]+\b`
2. **方法2**：split() + 手动过滤
3. **方法3**：多重正则模式

**验证结果分级：**

- ✅ **验证通过**：三种方法结果完全一致
- ⚠️ **轻微差异**：差异 ≤2个词（可接受）
- ⚠️ **中等差异**：差异 3-5个词（需注意）
- ❌ **显著差异**：差异 >5个词（需人工复核）

## 📁 项目结构

```
4词汇统计streamlit/
├── app.py                      # Streamlit主程序
├── requirements.txt            # 依赖包
├── README.md                   # 项目说明
├── utils/                      # 工具模块
│   ├── __init__.py
│   ├── verify.py              # 三遍验证模块
│   ├── word_analyzer.py       # 词汇分析模块
│   ├── text_cleaner.py        # 文本清理模块
│   ├── book_processor.py      # 书籍处理模块
│   └── txt_exporter.py        # TXT导出模块
└── input/                      # 测试文件（可选）
```

## 🛠️ 技术栈

- **Python 3.7+**
- **Streamlit** - Web界面框架
- **正则表达式** - 文本处理
- **Unicode** - 中文字符识别

## 📝 处理规则

### 1双语文件
- 移除所有中文字符（`\u4e00-\u9fff`）
- 移除中文标点（`\u3000-\u303f`）
- 移除全角字符（`\uff00-\uffef`）
- 只保留英文单词

### 2原文文件
- 纯英文文本，无需特殊处理
- 直接统计英文单词

### 3外教文件
- 移除Markdown粗体标记（`**text**`）
- 移除所有中文字符和标点
- 保留对话人名（Sally、Pete等）
- 只统计英文单词

## 🌐 部署到Streamlit Cloud

1. **推送到GitHub**

```bash
git init
git add .
git commit -m "Initial commit"
git push origin main
```

2. **部署到Streamlit Cloud**

- 访问 https://share.streamlit.io/
- 连接GitHub仓库
- 选择 `app.py` 作为主文件
- 点击部署

3. **分享链接**

部署完成后，获得公开访问链接，分享给同事使用。

## 📄 输出报告格式

TXT报告包含以下内容：

1. **汇总统计**：所有文件的总词数、唯一词数对比
2. **详细统计**：每种类型的完整统计信息
3. **唯一词列表**：按字母顺序排列的所有唯一单词
4. **验证详情**：三遍验证的详细结果
5. **高频词汇**：Top 20 高频词及出现次数

## ❓ 常见问题

**Q: 支持哪些文件格式？**  
A: 支持 .txt 和 .md 格式

**Q: 如何处理中英文混合的文档？**  
A: 自动使用Unicode范围精确过滤中文字符

**Q: 数字和符号会被统计吗？**  
A: 不会，只统计纯英文字母组成的单词

**Q: 大小写敏感吗？**  
A: 不敏感，"The"和"the"算作同一个单词

**Q: Sally、Pete等人名会被统计吗？**  
A: 会，它们是英文单词的一部分

## 📞 技术支持

如有问题或建议，请联系开发团队。

## 📖 相关文档

- [改进说明](改进说明.md) - 最新改进和优化详情
- [缩写处理规则说明](缩写处理规则说明.md) - 缩写处理规则详解
- [快速开始指南](快速开始.md) - 5分钟上手
- [部署指南](部署指南.md) - 部署到Streamlit Cloud
- [项目说明](项目说明.md) - 技术架构和详细说明

## 📜 版本历史

- **v1.1** (2025-11-14)
  - ✅ 新增智能缩写处理（70+个标准缩写）
  - ✅ 自动过滤说话人标记（**Sally:**、**Pete:**）
  - ✅ 优化验证策略（优先使用智能缩写方法）
  - ✅ 新增详细文档（改进说明、缩写处理规则）

- **v1.0** (2025-11-14)
  - 初始版本
  - 支持三种文件类型
  - 三遍验证机制
  - TXT报告导出

